{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6500b607-6b30-4004-99bc-1c1a59a8e4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEnsemble methods are techniques that create multiple models and then combine them to produce improved results.\\nEnsemble methods usually produces more accurate solutions than a single model would.\\nThis has been the case in a number of machine learning competitions, where the winning solutions used ensemble methods.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 1 :\n",
    "\"\"\"\n",
    "Ensemble methods are techniques that create multiple models and then combine them to produce improved results.\n",
    "Ensemble methods usually produces more accurate solutions than a single model would.\n",
    "This has been the case in a number of machine learning competitions, where the winning solutions used ensemble methods.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5af8a69-7954-481f-beb3-0afbbbd3ba09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEnsemble methods are ideal for reducing the variance in models, thereby increasing the accuracy of predictions.\\nThe variance is eliminated when multiple models are combined to form a single prediction that is chosen from all\\nother possible predictions from the combined models.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 2 :\n",
    "\"\"\"\n",
    "Ensemble methods are ideal for reducing the variance in models, thereby increasing the accuracy of predictions.\n",
    "The variance is eliminated when multiple models are combined to form a single prediction that is chosen from all\n",
    "other possible predictions from the combined models.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c128c61e-a5dc-47b5-aa0d-5448715ce20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBagging, also known as bootstrap aggregation, is the ensemble learning method that is commonly used to reduce \\nvariance within a noisy dataset. In bagging, a random sample of data in a training set is selected with \\nreplacement—meaning that the individual data points can be chosen more than once.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 3 :\n",
    "\"\"\"\n",
    "Bagging, also known as bootstrap aggregation, is the ensemble learning method that is commonly used to reduce \n",
    "variance within a noisy dataset. In bagging, a random sample of data in a training set is selected with \n",
    "replacement—meaning that the individual data points can be chosen more than once.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa876522-e3da-444a-b56b-29bc2b75323a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBoosting is a method used in machine learning to reduce errors in predictive data analysis.\\nData scientists train machine learning software, called machine learning models, on labeled data to\\nmake guesses about unlabeled data.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 4 :\n",
    "\"\"\"\n",
    "Boosting is a method used in machine learning to reduce errors in predictive data analysis.\n",
    "Data scientists train machine learning software, called machine learning models, on labeled data to\n",
    "make guesses about unlabeled data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5095b42f-70f6-4abb-910b-ab9a827d1e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBenefits of ensemble methods :\\nEnsemble methods have higher predictive accuracy, compared to the individual models.\\nEnsemble methods are very useful when there is both linear and non-linear type of data in the dataset;\\ndifferent models can be combined to handle this type of data.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 5 :\n",
    "\"\"\"\n",
    "Benefits of ensemble methods :\n",
    "Ensemble methods have higher predictive accuracy, compared to the individual models.\n",
    "Ensemble methods are very useful when there is both linear and non-linear type of data in the dataset;\n",
    "different models can be combined to handle this type of data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9557f46-512a-4ec6-a69c-d83fb6b65f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThere are two main reasons to use an ensemble over a single model, and they are related; they are: \\nPerformance: An ensemble can make better predictions and achieve better performance than any single contributing model.\\nRobustness: An ensemble reduces the spread or dispersion of the predictions and model performance.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 6 :\n",
    "\"\"\"\n",
    "There are two main reasons to use an ensemble over a single model, and they are related; they are: \n",
    "Performance: An ensemble can make better predictions and achieve better performance than any single contributing model.\n",
    "Robustness: An ensemble reduces the spread or dispersion of the predictions and model performance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d257c03a-785d-469d-9bdc-5ccc1033359d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nVariance: It is obtained by the sum of squared distances between a data point and the mean for each \\ndata point divided by the number of data points.\\n\\nStandard Deviation: It is a measurement that shows us how our data points spread out from the mean. \\nIt is obtained by taking the square root of the variance.\\n\\nCumulative Distribution Function: It can be used on any kind of variable X(discrete, continuous, etc.). \\nIt shows us the probability distribution of a variable. Therefore allowing us to interpret the probability of a \\nvalue less than or equal to x from a given probability distribution\\n\\nEmpirical Cumulative Distribution Function: Also known as Empirical Distribution Function.\\nThe only difference between CDF and ECDF is, while the former shows us the hypothetical distribution of any given population,\\nthe latter is based on our observed data.\\n\\nProbability Density Function: It shows us the distribution of continuous variables.\\nThe area under the curve gives us the probability so that the area must always be equal to 1\\n\\nNormal Distribution: Also known as Gaussian Distribution.\\nIt is the most important probability distribution function in statistics which is bell-shaped and symmetric.\\n\\nConfidence Interval: It is the range in which the values likely to exist in the population. \\nIt is estimated from the original sample and usually defined as 95% confidence but it may differ.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 7 :\n",
    "\"\"\"\n",
    "Variance: It is obtained by the sum of squared distances between a data point and the mean for each \n",
    "data point divided by the number of data points.\n",
    "\n",
    "Standard Deviation: It is a measurement that shows us how our data points spread out from the mean. \n",
    "It is obtained by taking the square root of the variance.\n",
    "\n",
    "Cumulative Distribution Function: It can be used on any kind of variable X(discrete, continuous, etc.). \n",
    "It shows us the probability distribution of a variable. Therefore allowing us to interpret the probability of a \n",
    "value less than or equal to x from a given probability distribution\n",
    "\n",
    "Empirical Cumulative Distribution Function: Also known as Empirical Distribution Function.\n",
    "The only difference between CDF and ECDF is, while the former shows us the hypothetical distribution of any given population,\n",
    "the latter is based on our observed data.\n",
    "\n",
    "Probability Density Function: It shows us the distribution of continuous variables.\n",
    "The area under the curve gives us the probability so that the area must always be equal to 1\n",
    "\n",
    "Normal Distribution: Also known as Gaussian Distribution.\n",
    "It is the most important probability distribution function in statistics which is bell-shaped and symmetric.\n",
    "\n",
    "Confidence Interval: It is the range in which the values likely to exist in the population. \n",
    "It is estimated from the original sample and usually defined as 95% confidence but it may differ.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ed90eb-53dd-4760-896f-1f2776ef64f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn statistics, bootstrapping describes the process of resampling a data set to create many simulated samples.\\nThis approach enables users to calculate standard errors, perform hypothesis testing and construct confidence \\nintervals for different types of sample statistics.\\nBootstrap Method :\\nChoose a number of bootstrap samples to perform.\\nChoose a sample size.\\nFor each bootstrap sample. Draw a sample with replacement with the chosen size. Calculate the statistic on the sample.\\nCalculate the mean of the calculated sample statistics.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 8 :\n",
    "\"\"\"\n",
    "In statistics, bootstrapping describes the process of resampling a data set to create many simulated samples.\n",
    "This approach enables users to calculate standard errors, perform hypothesis testing and construct confidence \n",
    "intervals for different types of sample statistics.\n",
    "Bootstrap Method :\n",
    "Choose a number of bootstrap samples to perform.\n",
    "Choose a sample size.\n",
    "For each bootstrap sample. Draw a sample with replacement with the chosen size. Calculate the statistic on the sample.\n",
    "Calculate the mean of the calculated sample statistics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18551f51-56cb-42b2-ad16-46c683681b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMethods for Bootstrapping Confidence Intervals\\nStart with resampling with replacement from original data n times.\\nFor each bootstrap calculate mean x*.\\nCompute δ* = x* − x for each bootstrap sample (x is mean of original data), sort them from smallest to biggest.\\nChoose δ. 1 as the 90th percentile, δ.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 9 :\n",
    "\"\"\"\n",
    "Methods for Bootstrapping Confidence Intervals\n",
    "Start with resampling with replacement from original data n times.\n",
    "For each bootstrap calculate mean x*.\n",
    "Compute δ* = x* − x for each bootstrap sample (x is mean of original data), sort them from smallest to biggest.\n",
    "Choose δ. 1 as the 90th percentile, δ.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
